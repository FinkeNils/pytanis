{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import logging\n",
    "import structlog\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import tomli\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")\n",
    "sns.set(rc={\"figure.figsize\": (12, 6.)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_columns\", 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.WARNING, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytanis\n",
    "from pytanis import GSheetsClient, PretalxClient\n",
    "from pytanis.google import Scope, mark_rows, gsheet_col\n",
    "from pytanis.review import read_assignment_as_df, save_assignments_as_json, Col\n",
    "from pytanis.pretalx import subs_as_df, reviews_as_df, speakers_as_df\n",
    "from pytanis.utils import implode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be aware that this notebook might only run with the following version\n",
    "pytanis.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import event-specific settings to don't have them here in the notebook\n",
    "with open('config.toml', 'rb') as fh:\n",
    "    cfg = tomli.load(fh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Reviews and all Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretalx_client = PretalxClient(blocking=True)\n",
    "subs_count, subs = pretalx_client.submissions(cfg['event_name'], params={'questions': 'all'})\n",
    "spkrs_count, spkrs = pretalx_client.speakers(cfg['event_name'], params={'questions': 'all'})\n",
    "revs_count, revs = pretalx_client.reviews(cfg['event_name'])\n",
    "subs, revs, spkrs = list(subs), list(revs), list(spkrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_df = subs_as_df(subs, with_questions=True)\n",
    "revs_df = reviews_as_df(revs)\n",
    "spkrs_df = speakers_as_df(spkrs, with_questions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join speakers and submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode on speakers and their names, join on speaker code and implode it again to have one submission per row\n",
    "subs_df = subs_df.explode([Col.speaker_code, Col.speaker_name])\n",
    "subs_df = pd.merge(subs_df, spkrs_df.drop(columns=[Col.speaker_name, Col.submission]), on=Col.speaker_code)\n",
    "subs_df = implode(subs_df, [col for col in spkrs_df if col not in [Col.submission]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance reviews by their personal mean (remove evaluation bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_means = revs_df.groupby([Col.pretalx_user], group_keys=False)[[Col.review_score]].mean().reset_index()\n",
    "revs_df[\"Avg Review Score\"] = pd.merge(revs_df[[Col.pretalx_user]], user_means, on=Col.pretalx_user, how='left')[Col.review_score]\n",
    "revs_df[\"Debiased Review Score\"] = revs_df[Col.review_score] - revs_df[\"Avg Review Score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join with submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_scores = pd.merge(subs_df, revs_df[[Col.submission, Col.review_score, \"Debiased Review Score\"]], on=Col.submission, how='left')\n",
    "avg_scores = avg_scores.groupby([Col.submission]).agg(**{Col.review_score: (Col.review_score, lambda x: x.tolist()),\n",
    "                                                         \"Avg Review Score\": (Col.review_score, 'mean'), \n",
    "                                                         \"Debiased Review Score\": (\"Debiased Review Score\", lambda x: [f\"{n:.2}\" for n in x.tolist()]), \n",
    "                                                         \"Avg Debiased Review Score\": (\"Debiased Review Score\", \"mean\"), \n",
    "                                                         Col.nreviews: (Col.review_score, 'count')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_df = pd.merge(subs_df, avg_scores, on=Col.submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get public voting results and join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# votes_df = pd.read_csv(\"./pyconde-pydata-berlin-2023-public-votes.csv\")\n",
    "# votes_df = votes_df.rename(columns={'code': Col.submission, 'score': Col.vote_score})\n",
    "# votes_df = votes_df.groupby(Col.submission).aggregate({Col.vote_score: lambda x: x.tolist()}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add a few informative columns\n",
    "# votes_df[Col.nvotes] = votes_df[Col.vote_score].str.len()\n",
    "# votes_df[\"Votes Sum > 1\"] = votes_df[Col.vote_score].map(lambda votes: sum([vote for vote in votes if vote > 1]))\n",
    "# votes_df[\"Avg Vote Score\"] = votes_df[Col.vote_score].map(lambda x: np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subs_df = pd.merge(subs_df, votes_df, on=Col.submission, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restructure the Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_df.drop(columns=['Q: Link to talk slides',\n",
    "                      'Q: X / Twitter handle',\n",
    "                      'Q: Mastodon',\n",
    "                      'Q: I have read and agree to the Code of Conduct', \n",
    "                      'Created',\n",
    "                      'Q: Picture',\n",
    "                      'Q: Public link to supporting material, e.g. videos, Github, etc.',\n",
    "                      'Q: Abstract as a tweet (X) or toot (Mastodon)',\n",
    "                      'Submission type id']\n",
    "            , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_df.rename(columns={'Q: Expected audience expertise: Python': 'Python expertise',\n",
    "                        'Q: Expected audience expertise: Domain': 'Domain expertise',\n",
    "                        'Q: I identify as a member of an underrepresented group': 'Underrepresented',\n",
    "                        'Q: Country of residence': 'Country',\n",
    "                        'Q: Github': 'Github',\n",
    "                        'Q: LinkedIn': 'LinkedIn',\n",
    "                        'Q: Homepage': 'Homepage',\n",
    "                        'Q: Company / Institute': 'Affiliation',\n",
    "                        'Q: Position / Job': 'Position',\n",
    "                        'Q: I will present my talk on site': 'Onsite talk',\n",
    "                        'Q: Notes for reviewers only': 'Reviewer notes',\n",
    "                        'Q: I hereby declare that this proposal is my own original work': 'Original work',\n",
    "                        'Q: Did you use an LLM, e.g. ChatGPT, to help you with this proposal?': 'ChatGPT used',\n",
    "                        'Q: How should we address you?': 'Pronouns',\n",
    "                        'Q: I am open to receiving invitations from meet-up organizers to showcase my work at local meet-ups.': 'Meetup interested',\n",
    "                        'Q: City of residence': 'City'},\n",
    "              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split track in main and subtrack\n",
    "subs_df.insert(2, 'Main track', subs_df[Col.track].map(lambda x: x.split(\":\")[0] if not pd.isna(x) else x))\n",
    "subs_df[Col.track] = subs_df[Col.track].map(lambda x: x.split(\":\")[-1] if not pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have \"Pending state\" second but last column\n",
    "col = subs_df.pop(\"Pending state\")\n",
    "subs_df = pd.concat([subs_df, col.to_frame()], axis=1)\n",
    "# Have \"State\" second but last column\n",
    "col = subs_df.pop(\"State\")\n",
    "subs_df = pd.concat([subs_df, col.to_frame()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid multi-lines cells in GSheet\n",
    "subs_df['Reviewer notes'] = subs_df['Reviewer notes'].str.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subs_df.sort_values(\"Votes Sum > 1\", inplace=True, ascending=False)\n",
    "subs_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save it to GSheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make subsmission code a hyperlink\n",
    "subs_df[Col.submission] = subs_df[Col.submission].map(lambda sub: f'=HYPERLINK(\"https://pretalx.com/orga/event/{cfg[\"event_name\"]}/submissions/{sub}\", \"{sub}\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsheet_client = GSheetsClient(read_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsheet_client.save_df_as_gsheet(subs_df, cfg['selection_spread_id'], cfg['selection_work_name'], resize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some formatting\n",
    "from gspread_formatting import *\n",
    "\n",
    "worksheet = gsheet_client.gsheet(cfg['selection_spread_id'], cfg['selection_work_name'])\n",
    "set_frozen(worksheet, rows=1, cols=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_row_height(worksheet, \"1:500\", 50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, col in enumerate(subs_df.columns):\n",
    "    if col not in {'Title', 'Track', 'Speaker name', 'ChatGPT used', 'Reviewer notes', 'Biography', 'Position', 'LinkedIn', 'Github', 'Affiliation', 'Homepage'}:\n",
    "        continue\n",
    "    col_id = gsheet_col(idx)\n",
    "\n",
    "    fmt = cellFormat(\n",
    "        horizontalAlignment='LEFT',\n",
    "        wrapStrategy='WRAP'\n",
    "        )\n",
    "\n",
    "    format_cell_range(worksheet, col_id, fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = (subs_df[\"State\"] == 'rejected') | (subs_df[\"State\"] == 'withdrawn') | (subs_df[\"State\"] == 'canceled')\n",
    "mark_rows(worksheet, mask, 'firebrick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = (subs_df[\"State\"] == 'confirmed')\n",
    "mark_rows(worksheet, mask, 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = (subs_df[\"State\"] == 'accepted')\n",
    "mark_rows(worksheet, mask, 'limegreen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = (subs_df[\"Pending state\"] == 'rejected')\n",
    "mark_rows(worksheet, mask, 'lightcoral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = (subs_df[\"Pending state\"] == 'accepted')\n",
    "mark_rows(worksheet, mask, 'greenyellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirmed Talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conf_df = subs_df.loc[subs_df['State'] == 'confirmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gsheet_client.save_df_as_gsheet(conf_df, cfg['selection_spread_id'], cfg['confirmation_work_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#worksheet = gsheet_client.gsheet(cfg['selection_spread_id'], cfg['confirmation_work_name'])\n",
    "#set_frozen(worksheet, rows=1, cols=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
